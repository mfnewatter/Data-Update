{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Foods COVID Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: \n",
    "1. Process US Foods data (source = https://usfoods.precima.io/)\n",
    "2. Analyze data using COVID segmentation\n",
    "3. Compare sell-out (US Foods) to sell-in (McCain) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load libraries, initiate folder/file paths\n",
    "Run cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "#import teradatasql\n",
    "import pyodbc\n",
    "\n",
    "from distributor_transformation import transform_usfoods\n",
    "from sellout_model import process_list, analyze, add_time\n",
    "#from sellout_teradata import teradata_sales\n",
    "from sellout_import import import_usfoods, all_df\n",
    "from sellout_azure import azure_sellin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import File\n",
    "Run cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_connection():\n",
    "    server = 'mf-enterprise-dev-sql.46ac3df1733c.database.windows.net'\n",
    "    database = 'PWRAPPDB'\n",
    "    driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "    # Establish the database connection using AAD Integrated Authentication\n",
    "    conn_str = (\n",
    "        f'DRIVER={driver};'\n",
    "        f'SERVER=tcp:{server};'\n",
    "        f'DATABASE={database};'\n",
    "        'Authentication=ActiveDirectoryIntegrated'\n",
    "    )\n",
    "\n",
    "    cnxn = pyodbc.connect(conn_str)\n",
    "    cursor = cnxn.cursor()\n",
    "\n",
    "    return cnxn, cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = '''\n",
    "SELECT\n",
    "[Area],\n",
    "[Region],\n",
    "[Market],\n",
    "[State],\n",
    "[Pyramid Segment],\n",
    "[ASYS ID],\n",
    "[Manufacturer GTIN],\n",
    "[McCain SKU ID],\n",
    "[ASYS Description],\n",
    "[Week Beginning Date],\n",
    "SUM([LBS]) as LBS\n",
    "FROM [PWRAPPDB].[na_dist].[US_USFoods_Sellout]\n",
    "GROUP BY\n",
    "[Area],\n",
    "[Region],\n",
    "[Market],\n",
    "[State],\n",
    "[Pyramid Segment],\n",
    "[ASYS ID],\n",
    "[Manufacturer GTIN],\n",
    "[McCain SKU ID],\n",
    "[ASYS Description],\n",
    "[Week Beginning Date]\n",
    "'''\n",
    "\n",
    "cnxn, cursor = setup_connection() \n",
    "\n",
    "df = pd.read_sql_query(query_str, cnxn, parse_dates=['Week Beginning Date'])\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "cnxn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before adding dictionary: (906325, 11)\n",
      "Total before dictionary: 577827822.2299998\n",
      "Total after dictionary: 579381464.2700002\n",
      "Shape after adding dictionary: (909970, 22)\n",
      "Nothing missing for COVID Segmentation - L1\n",
      "The following products are missing:\n",
      "     ASYS ID Manufacturer GTIN McCain SKU ID         LBS\n",
      "0    1004527    10072714008143    1000010772   209088.00\n",
      "1    1008899    10072714008310    1000010868    10454.16\n",
      "2    1009467    10072714008204    1000010795     6224.08\n",
      "3    1009468    10072714008228    1000010809    56919.58\n",
      "4    1009550    10072714008129    1000010649    35024.96\n",
      "..       ...               ...           ...         ...\n",
      "282  9841260    50758108767183    1000006237  1496940.00\n",
      "283  9865114    10072714002103    1000001467    26064.00\n",
      "284   987032    10072714100946      80010094    21150.00\n",
      "285  9946046               NaN           NaN    15816.00\n",
      "286  9972388    10072714100106      70010010   688425.00\n",
      "\n",
      "[287 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_usfoods = transform_usfoods(df, 'US Foods - US.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported shape...(76223, 37)\n",
      "Final shape...(2002089, 13)\n"
     ]
    }
   ],
   "source": [
    "backup_path = r'C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Historical Sell-Out Sales\\Backups\\\\'\n",
    "\n",
    "_base = all_df(df_usfoods, backup_path, 'US FOODS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Region\n",
      "CPU times: total: 11.3 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "_list = []\n",
    "\n",
    "#Output 1: COVID L1 - List 0\n",
    "_list.append(['City', 'State Name','COVID Segmentation - L1','COVID Segmentation - L2','Restaurant Service Type','Consolidated Category'])\n",
    "\n",
    "#Output 2: COVID L1 - List 1\n",
    "_list.append(['State Name','COVID Segmentation - L1','COVID Segmentation - L2','Restaurant Service Type','SKU ID','Consolidated Category','L1 Product Hierarchy','L2 Product Hierarchy'])\n",
    "\n",
    "print(f'Processing Region', flush = True)\n",
    "output1 = %time process_list(_base, _list[0], 'US Foods')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Sell in vs Sell out\n",
      "Query ran for 6500002818 under sales org US01 for sales on or before 2024-01-21\n",
      "All done, took 11.0 seconds...\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "print(f'Processing Sell in vs Sell out', flush = True)\n",
    "output2 = azure_sellin(_base, 'US01', \"','\".join(['6500002818']), 'US Foods')\n",
    "\n",
    "print('All done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1.to_csv('files/sellout_region_us_foods.zip', compression='zip', index=False)\n",
    "output2.to_csv('files/sellout_sellin_us_foods.zip', compression='zip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_base.to_csv(backup_path + 'US FOODS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US Foods - Precima Combined File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting files from SharePoint\n",
    "1) Loop through directory folders and extract volume data from files named \"US Foods Update.csv\"\n",
    "2) Combine into one large dataframe and export to pickle file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 824184 entries, 1 to 76222\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   Market               824184 non-null  object \n",
      " 1   Pyramid Segment      824184 non-null  object \n",
      " 2   MFG #                824184 non-null  float64\n",
      " 3   ASYS #               824184 non-null  int64  \n",
      " 4   Product Description  824184 non-null  object \n",
      " 5   Year Week            824184 non-null  int64  \n",
      " 6   LB Current           824184 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 50.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_usf_prima(file_path):\n",
    "\n",
    "    # Read CSV file, only use certain columns\n",
    "    df = pd.read_csv(file_path, low_memory = False, thousands = ','\n",
    "                    ,usecols=['Market','Pyramid Segment','ASYS #','MFG #','Product Description','Year Week','LB Current'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Path to the directory you want to search\n",
    "directory_path = r'C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files'\n",
    "\n",
    "# Create blank dataframe\n",
    "us_foods = pd.DataFrame()\n",
    "\n",
    "# Loop through each folder and file in the directory\n",
    "for root, dirs, files in os.walk(directory_path):\n",
    "    for file in files:\n",
    "        # Check if \"SharedTable_weekly_cases\" is in the filename\n",
    "        if \"US Foods Update\" in file and file.lower().endswith('.csv'):\n",
    "\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(root, file)\n",
    "            \n",
    "            # Create dataframe from file\n",
    "            df = extract_usf_prima(file_path)\n",
    "\n",
    "            # Create a list of weeks in new data\n",
    "            weeks_in_data = df['Year Week'].tolist()\n",
    "\n",
    "            # If this is the first file then make dataframe same\n",
    "            if us_foods.empty:  \n",
    "                us_foods = df\n",
    "            \n",
    "            # If not first file then exclude weeks in dataframe and only keep new data\n",
    "            else:\n",
    "                us_foods = us_foods[~us_foods['Year Week'].isin(weeks_in_data)]\n",
    "                \n",
    "                us_foods = pd.concat([us_foods, df])\n",
    "\n",
    "print(us_foods.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Time from Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for time defintions file to convert time element to actual date (week beginning date)\n",
    "file_path = r'C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Data Dictionaries\\Time Definitions.xlsx'\n",
    "\n",
    "# Only use the time worksheet in the Excel file\n",
    "time_df = pd.read_excel(file_path, sheet_name='time')\n",
    "\n",
    "#time_df.info()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market</th>\n",
       "      <th>Pyramid Segment</th>\n",
       "      <th>MFG #</th>\n",
       "      <th>ASYS #</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Year Week</th>\n",
       "      <th>LB Current</th>\n",
       "      <th>Week Starting (Sun)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BISMARCK</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>5.075811e+13</td>\n",
       "      <td>9841260</td>\n",
       "      <td>FRENCH TOAST, STICK CKD FZN</td>\n",
       "      <td>202103</td>\n",
       "      <td>430.0</td>\n",
       "      <td>2021-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BISMARCK</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>1.007271e+13</td>\n",
       "      <td>4862793</td>\n",
       "      <td>SANDWICH, EGG BACN PTATO &amp; CHS</td>\n",
       "      <td>202103</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2021-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BISMARCK</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>1.007271e+13</td>\n",
       "      <td>8292377</td>\n",
       "      <td>POTATO, MSHD PTY SMILE SKNLS</td>\n",
       "      <td>202103</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2021-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BISMARCK</td>\n",
       "      <td>GOVERNMENT</td>\n",
       "      <td>1.007271e+13</td>\n",
       "      <td>1074871</td>\n",
       "      <td>POTATO, FF 3/8  SC BTRD BUTR</td>\n",
       "      <td>202103</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2021-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BISMARCK</td>\n",
       "      <td>GOVERNMENT</td>\n",
       "      <td>5.075811e+13</td>\n",
       "      <td>9841260</td>\n",
       "      <td>FRENCH TOAST, STICK CKD FZN</td>\n",
       "      <td>202103</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2021-01-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Market Pyramid Segment         MFG #   ASYS #   \n",
       "0  BISMARCK       EDUCATION  5.075811e+13  9841260  \\\n",
       "1  BISMARCK       EDUCATION  1.007271e+13  4862793   \n",
       "2  BISMARCK       EDUCATION  1.007271e+13  8292377   \n",
       "3  BISMARCK      GOVERNMENT  1.007271e+13  1074871   \n",
       "4  BISMARCK      GOVERNMENT  5.075811e+13  9841260   \n",
       "\n",
       "              Product Description  Year Week  LB Current Week Starting (Sun)  \n",
       "0     FRENCH TOAST, STICK CKD FZN     202103       430.0          2021-01-17  \n",
       "1  SANDWICH, EGG BACN PTATO & CHS     202103        60.0          2021-01-17  \n",
       "2    POTATO, MSHD PTY SMILE SKNLS     202103        48.0          2021-01-17  \n",
       "3    POTATO, FF 3/8  SC BTRD BUTR     202103       150.0          2021-01-17  \n",
       "4     FRENCH TOAST, STICK CKD FZN     202103        10.0          2021-01-17  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_foods_with_time = us_foods.merge(time_df[['Calendar Week Year','Week Starting (Sun)']], \n",
    "                          left_on = 'Year Week',\n",
    "                          right_on='Calendar Week Year')\n",
    "\n",
    "us_foods_with_time.drop(columns={'Calendar Week Year'}, inplace=True)\n",
    "\n",
    "us_foods_with_time.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export File as Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Sell-Out\\us_foods_precima.zip'\n",
    "\n",
    "us_foods_with_time.to_csv(file_path, index=False, compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Old Data - Precima File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "precima = pd.read_csv(r'C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Source Files\\us_foods_precima.zip', \n",
    "                      parse_dates=['Week Starting (Sun)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Market', 'Pyramid Segment', 'MFG #', 'ASYS #', 'Product Description',\n",
      "       'Year Week', 'LBS', 'Week Beginning Date'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 824184 entries, 0 to 824183\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count   Dtype         \n",
      "---  ------               --------------   -----         \n",
      " 0   Market               824184 non-null  object        \n",
      " 1   Pyramid Segment      824184 non-null  object        \n",
      " 2   MFG #                824184 non-null  float64       \n",
      " 3   ASYS #               824184 non-null  int64         \n",
      " 4   Product Description  824184 non-null  object        \n",
      " 5   Year Week            824184 non-null  int64         \n",
      " 6   LBS                  824184 non-null  float64       \n",
      " 7   Week Beginning Date  824184 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(3)\n",
      "memory usage: 56.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rename_columns = {\n",
    "    'LB Current':'LBS',\n",
    "    'Week Starting (Sun)':'Week Beginning Date'\n",
    "}\n",
    "\n",
    "precima.rename(columns=rename_columns, inplace=True)\n",
    "\n",
    "print(precima.columns)\n",
    "print(precima.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for time defintions file to convert time element to actual date (week beginning date)\n",
    "file_path = r'C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Data Dictionaries\\US Foods - US.xlsx'\n",
    "\n",
    "segments = pd.read_excel(file_path, sheet_name='Segment Mapping v2')\n",
    "regions = pd.read_excel(file_path, sheet_name='Region Mapping')\n",
    "skus = pd.read_excel(file_path, sheet_name='SKU Mapping v3', dtype={'Manufacturer Item Number':'str'})\n",
    "\n",
    "#print(segments.info())\n",
    "#print(regions.info())\n",
    "#print(skus.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASYS</th>\n",
       "      <th>Manufacturer Item Number</th>\n",
       "      <th>Merch Category</th>\n",
       "      <th>PIM Group</th>\n",
       "      <th>Product</th>\n",
       "      <th>Consolidated Category</th>\n",
       "      <th>L1 Product Hierarchy</th>\n",
       "      <th>L2 Product Hierarchy</th>\n",
       "      <th>McCain SKU ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5601641.0</td>\n",
       "      <td>10072714003742</td>\n",
       "      <td>COOKIES</td>\n",
       "      <td>COOKIES, READY TO EAT, FROZEN</td>\n",
       "      <td>COOKIE, SNDWH CHOC VNL CRM</td>\n",
       "      <td>Prepared Foods</td>\n",
       "      <td>Local Portfolio</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>1000004861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10072714006040</td>\n",
       "      <td>COOKIES</td>\n",
       "      <td>COOKIES, READY TO EAT, FROZEN</td>\n",
       "      <td>COOKIE, SNDWH CHOC VNL CRM</td>\n",
       "      <td>Prepared Foods</td>\n",
       "      <td>Local Portfolio</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>1000007909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10072714105224</td>\n",
       "      <td>DESSERT BARS</td>\n",
       "      <td>BROWNIES, FROZEN</td>\n",
       "      <td>BROWNIE, DBL CHOC NOT ICED</td>\n",
       "      <td>Prepared Foods</td>\n",
       "      <td>Local Portfolio</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>15010522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9771668.0</td>\n",
       "      <td>6007713363174</td>\n",
       "      <td>FRIED APPETIZERS</td>\n",
       "      <td>APPETIZERS, ONIONS, BREADED &amp; BATTERED</td>\n",
       "      <td>ONION CHIPS-MCCAIN-1000000689</td>\n",
       "      <td>Prepared Foods</td>\n",
       "      <td>Appetizer</td>\n",
       "      <td>Onion Shapes</td>\n",
       "      <td>1000000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10041493107606</td>\n",
       "      <td>FRIED APPETIZERS</td>\n",
       "      <td>APPETIZERS, ONIONS, BREADED &amp; BATTERED</td>\n",
       "      <td>ONION RING, BTRD BEER EX THCK</td>\n",
       "      <td>Prepared Foods</td>\n",
       "      <td>Appetizer</td>\n",
       "      <td>Onion Rings</td>\n",
       "      <td>10210732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>9040775.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APPETIZER, CHS MOZZ BTRD BEER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>9071986.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POTATO, FF 1/2 CC FCY FZN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>9946046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ONION SLIVERS BREADED FZN BAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>950099.0</td>\n",
       "      <td>11204530026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1120453002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>6458749.0</td>\n",
       "      <td>6007701210404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>445 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ASYS Manufacturer Item Number    Merch Category   \n",
       "0    5601641.0           10072714003742           COOKIES  \\\n",
       "1          NaN           10072714006040           COOKIES   \n",
       "2          NaN           10072714105224      DESSERT BARS   \n",
       "3    9771668.0            6007713363174  FRIED APPETIZERS   \n",
       "4          NaN           10041493107606  FRIED APPETIZERS   \n",
       "..         ...                      ...               ...   \n",
       "440  9040775.0                      NaN               NaN   \n",
       "441  9071986.0                      NaN               NaN   \n",
       "442  9946046.0                      NaN               NaN   \n",
       "443   950099.0              11204530026               NaN   \n",
       "444  6458749.0            6007701210404               NaN   \n",
       "\n",
       "                                  PIM Group                        Product   \n",
       "0             COOKIES, READY TO EAT, FROZEN     COOKIE, SNDWH CHOC VNL CRM  \\\n",
       "1             COOKIES, READY TO EAT, FROZEN     COOKIE, SNDWH CHOC VNL CRM   \n",
       "2                          BROWNIES, FROZEN     BROWNIE, DBL CHOC NOT ICED   \n",
       "3    APPETIZERS, ONIONS, BREADED & BATTERED  ONION CHIPS-MCCAIN-1000000689   \n",
       "4    APPETIZERS, ONIONS, BREADED & BATTERED  ONION RING, BTRD BEER EX THCK   \n",
       "..                                      ...                            ...   \n",
       "440                                     NaN  APPETIZER, CHS MOZZ BTRD BEER   \n",
       "441                                     NaN      POTATO, FF 1/2 CC FCY FZN   \n",
       "442                                     NaN  ONION SLIVERS BREADED FZN BAG   \n",
       "443                                     NaN                            NaN   \n",
       "444                                     NaN                            NaN   \n",
       "\n",
       "    Consolidated Category L1 Product Hierarchy L2 Product Hierarchy   \n",
       "0          Prepared Foods      Local Portfolio               Bakery  \\\n",
       "1          Prepared Foods      Local Portfolio               Bakery   \n",
       "2          Prepared Foods      Local Portfolio               Bakery   \n",
       "3          Prepared Foods            Appetizer         Onion Shapes   \n",
       "4          Prepared Foods            Appetizer          Onion Rings   \n",
       "..                    ...                  ...                  ...   \n",
       "440                   NaN                  NaN                  NaN   \n",
       "441                   NaN                  NaN                  NaN   \n",
       "442                   NaN                  NaN                  NaN   \n",
       "443                   NaN                  NaN                  NaN   \n",
       "444                   NaN                  NaN                  NaN   \n",
       "\n",
       "    McCain SKU ID  \n",
       "0      1000004861  \n",
       "1      1000007909  \n",
       "2        15010522  \n",
       "3      1000000689  \n",
       "4        10210732  \n",
       "..            ...  \n",
       "440           NaN  \n",
       "441           NaN  \n",
       "442           NaN  \n",
       "443    1120453002  \n",
       "444           NaN  \n",
       "\n",
       "[445 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows = 0\n"
     ]
    }
   ],
   "source": [
    "precima_regions = precima.merge(regions, how='left', on = 'Market')\n",
    "\n",
    "missing_rows = precima_regions['Region'].isna().sum()\n",
    "\n",
    "print(f'Missing rows = {missing_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows = 0\n"
     ]
    }
   ],
   "source": [
    "precima_skus = precima_regions.merge(skus, how='left', left_on = 'ASYS #', right_on = 'ASYS')\n",
    "\n",
    "missing_rows = precima_skus['ASYS'].isna().sum()\n",
    "\n",
    "print(f'Missing rows = {missing_rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean ASYS column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Market', 'Pyramid Segment', 'MFG #', 'ASYS #', 'Product Description',\n",
      "       'Year Week', 'LBS', 'Week Beginning Date', 'Region', 'Area', 'State',\n",
      "       'ASYS', 'Manufacturer Item Number', 'Merch Category', 'PIM Group',\n",
      "       'Product', 'Consolidated Category', 'L1 Product Hierarchy',\n",
      "       'L2 Product Hierarchy', 'McCain SKU ID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "precima_skus['ASYS'] = precima_skus['ASYS'].astype(int).astype(str)\n",
    "\n",
    "print(precima_skus.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 824184 entries, 0 to 824183\n",
      "Data columns (total 21 columns):\n",
      " #   Column                                           Non-Null Count   Dtype         \n",
      "---  ------                                           --------------   -----         \n",
      " 0   Area                                             824184 non-null  object        \n",
      " 1   Region                                           824184 non-null  object        \n",
      " 2   Market                                           824184 non-null  object        \n",
      " 3   State                                            824184 non-null  object        \n",
      " 4   Pyramid Segment                                  824184 non-null  object        \n",
      " 5   COVID Segmentation - L1                          824184 non-null  object        \n",
      " 6   COVID Segmentation - L2                          824184 non-null  object        \n",
      " 7   COVID Segmentation - (Restaurants)               824184 non-null  object        \n",
      " 8   COVID Segmentation - (Restaurants: Sub-Segment)  824184 non-null  object        \n",
      " 9   Restaurant Service Type                          824184 non-null  object        \n",
      " 10  ASYS                                             824184 non-null  object        \n",
      " 11  Product                                          824184 non-null  object        \n",
      " 12  Manufacturer Item Number                         824041 non-null  object        \n",
      " 13  Merch Category                                   824014 non-null  object        \n",
      " 14  PIM Group                                        824041 non-null  object        \n",
      " 15  McCain SKU ID                                    823806 non-null  object        \n",
      " 16  Consolidated Category                            824041 non-null  object        \n",
      " 17  L1 Product Hierarchy                             824041 non-null  object        \n",
      " 18  L2 Product Hierarchy                             822788 non-null  object        \n",
      " 19  Week Starting (Sun)                              824184 non-null  datetime64[ns]\n",
      " 20  LBS                                              824184 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(19)\n",
      "memory usage: 132.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "columns_to_keep = ['Area', 'Region', 'Market','State','Pyramid Segment',\n",
    "                   'ASYS','Product', 'Manufacturer Item Number','McCain SKU ID','Week Starting (Sun)','LBS']\n",
    "\n",
    "file_path = r'C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Sell-Out\\us_foods_precima.pkl'\n",
    "\n",
    "precima_skus[columns_to_keep].to_pickle(file_path)\n",
    "\n",
    "print(precima_skus[columns_to_keep].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US Foods - New File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61354, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Market</th>\n",
       "      <th>Pyramid Segment</th>\n",
       "      <th>ASYS Code</th>\n",
       "      <th>GTIN</th>\n",
       "      <th>MFG Number</th>\n",
       "      <th>Week Starting (Sun)</th>\n",
       "      <th>LBS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>ANCHORAGE-4190</td>\n",
       "      <td>HOSPITALITY</td>\n",
       "      <td>4180733</td>\n",
       "      <td>10072714802550</td>\n",
       "      <td>BCI00255</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>ANCHORAGE-4190</td>\n",
       "      <td>HOSPITALITY</td>\n",
       "      <td>6364970</td>\n",
       "      <td>10072714102346</td>\n",
       "      <td>80010234</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>ANCHORAGE-4190</td>\n",
       "      <td>INDEPENDENT RESTAURATEURS</td>\n",
       "      <td>987149</td>\n",
       "      <td>10072714036023</td>\n",
       "      <td>MCX03602</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>ANCHORAGE-4190</td>\n",
       "      <td>NATIONAL CHAINS</td>\n",
       "      <td>8332298</td>\n",
       "      <td>10072714101950</td>\n",
       "      <td>82910195</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>408.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Area          Market            Pyramid Segment  ASYS Code   \n",
       "1  ANCHORAGE  ANCHORAGE-4190                HOSPITALITY    4180733  \\\n",
       "2  ANCHORAGE  ANCHORAGE-4190                HOSPITALITY    6364970   \n",
       "3  ANCHORAGE  ANCHORAGE-4190  INDEPENDENT RESTAURATEURS     987149   \n",
       "4  ANCHORAGE  ANCHORAGE-4190            NATIONAL CHAINS    8332298   \n",
       "\n",
       "             GTIN MFG Number Week Starting (Sun)    LBS  \n",
       "1  10072714802550   BCI00255          2024-01-21   60.0  \n",
       "2  10072714102346   80010234          2024-01-21   30.0  \n",
       "3  10072714036023   MCX03602          2024-01-21  102.0  \n",
       "4  10072714101950   82910195          2024-01-21  408.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_usf_sharedtable(file_path):\n",
    "    df = pd.read_csv(file_path, low_memory = False, thousands = ',')\n",
    "\n",
    "    # Last column name = date (2024-03-24 11) with 11 being the week number of the year\n",
    "    last_column = df.columns[-1]\n",
    "\n",
    "    # Pattern to capture date in last_column\n",
    "    pattern = r'(\\d{4}-\\d{2}-\\d{2})'\n",
    "\n",
    "    # Extract date using regex\n",
    "    week_begin = re.search(pattern, last_column).group(1)\n",
    "\n",
    "    # Change data types\n",
    "    df = df.astype({\n",
    "        'GTIN':'str',\n",
    "        'MFG Number':'str',\n",
    "        last_column: 'float'\n",
    "    })\n",
    "\n",
    "    # Rename LBS column\n",
    "    df.rename(columns={last_column: 'LBS', 'Week Beginning':'Week Starting (Sun)'}, inplace=True)\n",
    "\n",
    "    # Add week beginning column\n",
    "    df['Week Starting (Sun)'] = pd.to_datetime(week_begin)\n",
    "\n",
    "    # Drop NaN rows and realign dataframe\n",
    "    df = df.dropna(subset='Market')[['Area', 'Market', 'Pyramid Segment', 'ASYS Code', 'GTIN', 'MFG Number','Week Starting (Sun)', 'LBS']]\n",
    "\n",
    "    # Drop .0 from ASYS Code\n",
    "    #df['ASYS Code'] = df['ASYS Code'].astype('int').astype('str')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Path to the directory you want to search\n",
    "directory_path = r'C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Weekly Update Files'\n",
    "\n",
    "# Create blank dataframe\n",
    "us_foods = pd.DataFrame()\n",
    "\n",
    "# Loop through each folder and file in the directory\n",
    "for root, dirs, files in os.walk(directory_path):\n",
    "    for file in files:\n",
    "        # Check if \"SharedTable_weekly_cases\" is in the filename\n",
    "        if \"SharedTable_weekly_cases\" in file:\n",
    "\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(root, file)\n",
    "            \n",
    "            df = extract_usf_sharedtable(file_path)\n",
    "\n",
    "            us_foods = pd.concat([us_foods, df])\n",
    "\n",
    "# Drop rows that contain '-'\n",
    "rows_to_drop = us_foods[us_foods['Pyramid Segment'].str.contains('-')].index\n",
    "us_foods.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "us_foods['ASYS Code'] = us_foods['ASYS Code'].astype(int)\n",
    "\n",
    "print(us_foods.shape)\n",
    "\n",
    "us_foods.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Area', 'Market', 'Pyramid Segment', 'ASYS Code', 'GTIN', 'MFG Number',\n",
       "       'Week Starting (Sun)', 'LBS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_foods.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for time defintions file to convert time element to actual date (week beginning date)\n",
    "file_path = r'C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Data Dictionaries\\US Foods - US.xlsx'\n",
    "\n",
    "segments = pd.read_excel(file_path, sheet_name='Segment Mapping v2')\n",
    "regions = pd.read_excel(file_path, sheet_name='Region Mapping v2')\n",
    "\n",
    "skus = pd.read_excel(file_path, sheet_name='SKU Mapping v3', dtype={'Manufacturer Item Number':'str'})\n",
    "\n",
    "skus_clean = skus[~skus['ASYS'].isna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows = 0\n"
     ]
    }
   ],
   "source": [
    "us_foods_segments = us_foods.merge(segments, how='left', on='Pyramid Segment')\n",
    "\n",
    "missing_rows = us_foods_segments['COVID Segmentation - L1'].isna().sum()\n",
    "\n",
    "print(f'Missing rows = {missing_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows = 0\n"
     ]
    }
   ],
   "source": [
    "us_foods_regions = us_foods_segments.merge(regions[['Market','Region','State']], how='left', on='Market')\n",
    "\n",
    "missing_rows = us_foods_regions['State'].isna().sum()\n",
    "\n",
    "print(f'Missing rows = {missing_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing rows = 0\n"
     ]
    }
   ],
   "source": [
    "skus_clean['ASYS'] = skus_clean['ASYS'].astype(int)\n",
    "\n",
    "us_foods_skus = us_foods_regions.merge(skus_clean, how='left', left_on='ASYS Code', right_on = 'ASYS')\n",
    "\n",
    "us_foods_skus['ASYS'] = us_foods_skus['ASYS'].astype(str)\n",
    "\n",
    "missing_rows = us_foods_skus['ASYS'].isna().sum()\n",
    "\n",
    "print(f'Missing rows = {missing_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Area', 'Market', 'Pyramid Segment', 'ASYS Code', 'GTIN', 'MFG Number',\n",
       "       'Week Starting (Sun)', 'LBS', 'COVID Segmentation - L1',\n",
       "       'COVID Segmentation - L2', 'COVID Segmentation - (Restaurants)',\n",
       "       'COVID Segmentation - (Restaurants: Sub-Segment)',\n",
       "       'Restaurant Service Type', 'Region', 'State', 'ASYS',\n",
       "       'Manufacturer Item Number', 'Merch Category', 'PIM Group', 'Product',\n",
       "       'Consolidated Category', 'L1 Product Hierarchy', 'L2 Product Hierarchy',\n",
       "       'McCain SKU ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_foods_skus.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61354 entries, 0 to 61353\n",
      "Data columns (total 21 columns):\n",
      " #   Column                                           Non-Null Count  Dtype         \n",
      "---  ------                                           --------------  -----         \n",
      " 0   Area                                             61354 non-null  object        \n",
      " 1   Region                                           61354 non-null  object        \n",
      " 2   Market                                           61354 non-null  object        \n",
      " 3   State                                            61354 non-null  object        \n",
      " 4   Pyramid Segment                                  61354 non-null  object        \n",
      " 5   COVID Segmentation - L1                          61354 non-null  object        \n",
      " 6   COVID Segmentation - L2                          61354 non-null  object        \n",
      " 7   COVID Segmentation - (Restaurants)               61354 non-null  object        \n",
      " 8   COVID Segmentation - (Restaurants: Sub-Segment)  61354 non-null  object        \n",
      " 9   Restaurant Service Type                          61354 non-null  object        \n",
      " 10  ASYS                                             61354 non-null  object        \n",
      " 11  Product                                          61349 non-null  object        \n",
      " 12  Manufacturer Item Number                         61354 non-null  object        \n",
      " 13  Merch Category                                   61349 non-null  object        \n",
      " 14  PIM Group                                        61349 non-null  object        \n",
      " 15  McCain SKU ID                                    61106 non-null  object        \n",
      " 16  Consolidated Category                            61345 non-null  object        \n",
      " 17  L1 Product Hierarchy                             61345 non-null  object        \n",
      " 18  L2 Product Hierarchy                             60502 non-null  object        \n",
      " 19  Week Starting (Sun)                              61354 non-null  datetime64[ns]\n",
      " 20  LBS                                              61354 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(19)\n",
      "memory usage: 9.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "columns_to_keep = ['Area', 'Region', 'Market','State','Pyramid Segment',\n",
    "                   'COVID Segmentation - L1', 'COVID Segmentation - L2',\n",
    "                   'COVID Segmentation - (Restaurants)','COVID Segmentation - (Restaurants: Sub-Segment)',\n",
    "                   'Restaurant Service Type','ASYS', 'Product', 'Manufacturer Item Number',\n",
    "                   'Merch Category','PIM Group','McCain SKU ID','Consolidated Category', 'L1 Product Hierarchy','L2 Product Hierarchy',\n",
    "                   'Week Starting (Sun)','LBS']\n",
    "\n",
    "print(us_foods_skus[columns_to_keep].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Precima with New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = r'C:/Users/newatter/OneDrive - McCain Foods Limited/Distributor Sell-Out/Source Files/us_foods_precima.pkl'\n",
    "\n",
    "precima = pd.read_pickle(source_path)\n",
    "\n",
    "us_foods_all = pd.concat([us_foods_skus[columns_to_keep], precima])\n",
    "\n",
    "file_name = 'us_foods'\n",
    "pickle_path = 'C:/Users/newatter/OneDrive - McCain Foods Limited/Distributor Sell-Out/Source Files'\n",
    "csv_path = 'C:/Users/newatter/OneDrive - McCain Foods Limited/Distributor Sell-Out/Sell-Out'\n",
    "\n",
    "#us_foods_all.to_pickle(f'{pickle_path}/{file_name}.pkl')\n",
    "\n",
    "compression_opts = dict(method='zip', archive_name=f'{file_name}.csv')\n",
    "\n",
    "us_foods_all.to_csv(f'{csv_path}/{file_name}.zip', index=False, \n",
    "                    compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 885538 entries, 0 to 824183\n",
      "Data columns (total 21 columns):\n",
      " #   Column                                           Non-Null Count   Dtype         \n",
      "---  ------                                           --------------   -----         \n",
      " 0   Area                                             885538 non-null  object        \n",
      " 1   Region                                           885538 non-null  object        \n",
      " 2   Market                                           885538 non-null  object        \n",
      " 3   State                                            885538 non-null  object        \n",
      " 4   Pyramid Segment                                  885538 non-null  object        \n",
      " 5   COVID Segmentation - L1                          885538 non-null  object        \n",
      " 6   COVID Segmentation - L2                          885538 non-null  object        \n",
      " 7   COVID Segmentation - (Restaurants)               885538 non-null  object        \n",
      " 8   COVID Segmentation - (Restaurants: Sub-Segment)  885538 non-null  object        \n",
      " 9   Restaurant Service Type                          885538 non-null  object        \n",
      " 10  ASYS                                             885538 non-null  object        \n",
      " 11  Product                                          885533 non-null  object        \n",
      " 12  Manufacturer Item Number                         885395 non-null  object        \n",
      " 13  Merch Category                                   885363 non-null  object        \n",
      " 14  PIM Group                                        885390 non-null  object        \n",
      " 15  McCain SKU ID                                    884912 non-null  object        \n",
      " 16  Consolidated Category                            885386 non-null  object        \n",
      " 17  L1 Product Hierarchy                             885386 non-null  object        \n",
      " 18  L2 Product Hierarchy                             883290 non-null  object        \n",
      " 19  Week Starting (Sun)                              885538 non-null  datetime64[ns]\n",
      " 20  LBS                                              885538 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(19)\n",
      "memory usage: 148.6+ MB\n"
     ]
    }
   ],
   "source": [
    "all_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "from sqlalchemy.engine import URL\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import regex as re\n",
    "\n",
    "class us_foods_sellout:\n",
    "    def __init__(self, file_path) -> None:\n",
    "        self.filepath = file_path\n",
    "        self.data = self.process_file()\n",
    "        self.data_import = self.filter_rows()\n",
    "        #self.delete_rows()\n",
    "        self.insert_rows()\n",
    "\n",
    "\n",
    "    def fill_in_missing_data(df):\n",
    "        file_path = r'C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Data Dictionaries\\US Foods - US.xlsx'\n",
    "        \n",
    "        regions = pd.read_excel(file_path, sheet_name='Region Mapping v2')\n",
    "\n",
    "        df = df.merge(regions[['Market','Market Clean','Region','State']], how='left', on='Market')\n",
    "\n",
    "        df.drop(['Market'], axis=1, inplace=True)\n",
    "        \n",
    "        df.rename(columns={'Market Clean':'Market'}, inplace=True)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def process_file(self):\n",
    "        df = pd.read_csv(self.filepath, low_memory = False, thousands = ',')\n",
    "\n",
    "        # Last column name = date (2024-03-24 11) with 11 being the week number of the year\n",
    "        last_column = df.columns[-1]\n",
    "\n",
    "        # Pattern to capture date in last_column\n",
    "        pattern = r'(\\d{4}-\\d{2}-\\d{2})'\n",
    "\n",
    "        # Extract date using regex\n",
    "        week_begin = re.search(pattern, last_column).group(1)\n",
    "\n",
    "        # Change data types\n",
    "        df = df.astype({\n",
    "            'GTIN':'str',\n",
    "            'MFG Number':'str',\n",
    "            last_column: 'float'\n",
    "        })\n",
    "\n",
    "        rename_columns = {\n",
    "            last_column: 'LBS', \n",
    "            'Week Beginning':'Week Beginning Date',\n",
    "            'ASYS Code':'ASYS ID',\n",
    "            'ASYS':'ASYS Description',\n",
    "            'GTIN':'Manufacturer GTIN',\n",
    "            'MFG Number':'McCain SKU ID'\n",
    "        }\n",
    "\n",
    "        # Rename columns\n",
    "        df.rename(columns=rename_columns, inplace=True)\n",
    "\n",
    "        # Add week beginning column\n",
    "        df['Week Beginning Date'] = pd.to_datetime(week_begin)\n",
    "\n",
    "        # Drop NaN rows and realign dataframe\n",
    "        df = df.dropna(subset='Market')\n",
    "\n",
    "        # Drop rows that contain '-'\n",
    "        rows_to_drop = df[df['Pyramid Segment'].str.contains('-')].index\n",
    "        df.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "        df['ASYS ID'] = df['ASYS ID'].astype(int).astype(str)\n",
    "\n",
    "        df = us_foods_sellout.fill_in_missing_data(df)\n",
    "\n",
    "        return df[['Area', 'Region', 'Market', 'State', 'Pyramid Segment', 'ASYS ID', 'ASYS Description', 'Manufacturer GTIN', 'McCain SKU ID','Week Beginning Date', 'LBS']]\n",
    "    \n",
    "    def setup_connection():\n",
    "        server = 'mf-enterprise-dev-sql.46ac3df1733c.database.windows.net'\n",
    "        database = 'PWRAPPDB'\n",
    "        driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "        # Establish the database connection using AAD Integrated Authentication\n",
    "        conn_str = (\n",
    "            f'DRIVER={driver};'\n",
    "            f'SERVER=tcp:{server};'\n",
    "            f'DATABASE={database};'\n",
    "            'Authentication=ActiveDirectoryIntegrated'\n",
    "        )\n",
    "\n",
    "        cnxn = pyodbc.connect(conn_str)\n",
    "        cursor = cnxn.cursor()\n",
    "\n",
    "        return cnxn, cursor\n",
    "\n",
    "\n",
    "    def filter_rows(self):\n",
    "        sql_select = \"\"\"\n",
    "        SELECT [Week Beginning Date] \n",
    "        FROM [na_dist].[US_USFoods_Sellout]\n",
    "        GROUP BY [Week Beginning Date] \"\"\"\n",
    "\n",
    "        cnxn, cursor = us_foods_sellout.setup_connection()\n",
    "\n",
    "        cursor.execute(sql_select)\n",
    "\n",
    "        # Fetch the results\n",
    "        results = cursor.fetchall()\n",
    "\n",
    "        # Convert the results into a list of dates\n",
    "        dates_in_db = [result[0] if result[0] is not None else None for result in results]\n",
    "        dates_in_db = pd.to_datetime([date for date in dates_in_db if date is not None])\n",
    "\n",
    "        # Commit the transactions\n",
    "        cnxn.commit()\n",
    "\n",
    "        \n",
    "        # Close the connection\n",
    "        cursor.close()\n",
    "        cnxn.close()\n",
    "\n",
    "        return self.data[~self.data['Week Beginning Date'].isin(dates_in_db)]\n",
    "\n",
    "    def setup_miengine():\n",
    "        server = 'mf-enterprise-dev-sql.46ac3df1733c.database.windows.net'\n",
    "        database = 'PWRAPPDB'\n",
    "        driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "        # Establish the database connection using AAD Integrated Authentication\n",
    "        conn_str = URL.create(\n",
    "            'mssql+pyodbc',\n",
    "            query={\n",
    "                'odbc_connect':(\n",
    "                    f'DRIVER={driver};'\n",
    "                    f'SERVER=tcp:{server};'\n",
    "                    f'DATABASE={database};'\n",
    "                    'Authentication=ActiveDirectoryIntegrated;'\n",
    "            )\n",
    "            }\n",
    "        )\n",
    "\n",
    "        engine = create_engine(conn_str, connect_args={\"autocommit\": True}, fast_executemany=True, use_insertmanyvalues=False)\n",
    "\n",
    "        return engine\n",
    "\n",
    "        \n",
    "    def insert_rows(self):\n",
    "        engine = us_foods_sellout.setup_miengine()\n",
    "\n",
    "        table_name = 'US_USFoods_Sellout'\n",
    "        schema_name = 'na_dist'\n",
    "\n",
    "        # If the table doesn't exist, it will be created automatically\n",
    "        self.data_import.to_sql(table_name, con=engine, schema=schema_name, if_exists='append', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.us_foods_sellout at 0x1a3411dbdc0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-01-21.csv'\n",
    "\n",
    "us_foods_sellout(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_export 2024-03-31.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_export 2024-04-07.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2023-12-31.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-01-07.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-01-14.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-01-21.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-01-28.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-02-04.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-02-11.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-02-18.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-02-25.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-03-03.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-03-10.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-03-17.csv\n",
      "C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files\\2024-04-05\\SharedTable_weekly_cases 2024-03-24.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# The path to the directory containing the folders\n",
    "directory_path = r'C:\\Users\\newatter\\OneDrive - McCain Foods Limited\\Distributor Sell-Out\\Weekly Update Files'\n",
    "\n",
    "# Loop through each folder and file in the directory\n",
    "for root, dirs, files in os.walk(directory_path):\n",
    "    for file in files:\n",
    "        # Check if \"SharedTable_weekly_cases\" is in the filename\n",
    "        if \"SharedTable_weekly\" in file or \"SharedTable_export\" in file:\n",
    "\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(root, file)\n",
    "            \n",
    "            print(file_path)\n",
    "\n",
    "            us_foods_sellout(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Precima data to SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "from sqlalchemy.engine import URL\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def setup_miengine():\n",
    "        server = 'mf-enterprise-dev-sql.46ac3df1733c.database.windows.net'\n",
    "        database = 'PWRAPPDB'\n",
    "        driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "        # Establish the database connection using AAD Integrated Authentication\n",
    "        conn_str = URL.create(\n",
    "            'mssql+pyodbc',\n",
    "            query={\n",
    "                'odbc_connect':(\n",
    "                    f'DRIVER={driver};'\n",
    "                    f'SERVER=tcp:{server};'\n",
    "                    f'DATABASE={database};'\n",
    "                    'Authentication=ActiveDirectoryIntegrated;'\n",
    "            )\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # use_insertmanyvalues=False\n",
    "        engine = create_engine(conn_str, \n",
    "                               connect_args={\"autocommit\": True}, \n",
    "                               fast_executemany=True,\n",
    "                               use_insertmanyvalues=False)\n",
    "\n",
    "        return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_rows(df):\n",
    "        engine = setup_miengine()\n",
    "\n",
    "        table_name = 'US_USFoods_Sellout'\n",
    "        schema_name = 'na_dist'\n",
    "\n",
    "        # If the table doesn't exist, it will be created automatically\n",
    "        df.to_sql(table_name, con=engine, schema=schema_name, if_exists='append', index=False, chunksize = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Area', 'Region', 'Market', 'State', 'Pyramid Segment',\n",
      "       'COVID Segmentation - L1', 'COVID Segmentation - L2',\n",
      "       'COVID Segmentation - (Restaurants)',\n",
      "       'COVID Segmentation - (Restaurants: Sub-Segment)',\n",
      "       'Restaurant Service Type', 'ASYS', 'Product',\n",
      "       'Manufacturer Item Number', 'Merch Category', 'PIM Group',\n",
      "       'McCain SKU ID', 'Consolidated Category', 'L1 Product Hierarchy',\n",
      "       'L2 Product Hierarchy', 'Week Starting (Sun)', 'LBS'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 824184 entries, 0 to 824183\n",
      "Data columns (total 21 columns):\n",
      " #   Column                                           Non-Null Count   Dtype         \n",
      "---  ------                                           --------------   -----         \n",
      " 0   Area                                             824184 non-null  object        \n",
      " 1   Region                                           824184 non-null  object        \n",
      " 2   Market                                           824184 non-null  object        \n",
      " 3   State                                            824184 non-null  object        \n",
      " 4   Pyramid Segment                                  824184 non-null  object        \n",
      " 5   COVID Segmentation - L1                          824184 non-null  object        \n",
      " 6   COVID Segmentation - L2                          824184 non-null  object        \n",
      " 7   COVID Segmentation - (Restaurants)               824184 non-null  object        \n",
      " 8   COVID Segmentation - (Restaurants: Sub-Segment)  824184 non-null  object        \n",
      " 9   Restaurant Service Type                          824184 non-null  object        \n",
      " 10  ASYS                                             824184 non-null  object        \n",
      " 11  Product                                          824184 non-null  object        \n",
      " 12  Manufacturer Item Number                         824041 non-null  object        \n",
      " 13  Merch Category                                   824014 non-null  object        \n",
      " 14  PIM Group                                        824041 non-null  object        \n",
      " 15  McCain SKU ID                                    823806 non-null  object        \n",
      " 16  Consolidated Category                            824041 non-null  object        \n",
      " 17  L1 Product Hierarchy                             824041 non-null  object        \n",
      " 18  L2 Product Hierarchy                             822788 non-null  object        \n",
      " 19  Week Starting (Sun)                              824184 non-null  datetime64[ns]\n",
      " 20  LBS                                              824184 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(19)\n",
      "memory usage: 132.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "source_path = r'C:/Users/newatter/OneDrive - McCain Foods Limited/Distributor Sell-Out/Source Files/us_foods_precima.pkl'\n",
    "\n",
    "precima = pd.read_pickle(source_path)\n",
    "\n",
    "print(precima.columns)\n",
    "print(precima.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Area', 'Region', 'Market', 'State', 'Pyramid Segment', 'ASYS ID',\n",
      "       'ASYS Description', 'Manufacturer GTIN', 'McCain SKU ID',\n",
      "       'Week Beginning Date', 'LBS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columns_to_keep = ['Area', 'Region', 'Market', 'State', 'Pyramid Segment','ASYS', 'Product',\n",
    "       'Manufacturer Item Number', 'McCain SKU ID','Week Starting (Sun)', 'LBS']\n",
    "\n",
    "rename_columns = {\n",
    "    'ASYS':'ASYS ID', \n",
    "    'Product':'ASYS Description',\n",
    "    'Manufacturer Item Number':'Manufacturer GTIN',\n",
    "    'Week Starting (Sun)':'Week Beginning Date'\n",
    "}\n",
    "\n",
    "usf = precima[columns_to_keep].rename(columns=rename_columns)\n",
    "\n",
    "print(usf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2021-01-17 00:00:00', '2021-01-24 00:00:00', '2021-01-31 00:00:00',\n",
       " '2021-02-14 00:00:00', '2021-02-07 00:00:00', '2021-02-21 00:00:00',\n",
       " '2021-02-28 00:00:00', '2021-03-07 00:00:00', '2021-03-14 00:00:00',\n",
       " '2021-03-28 00:00:00',\n",
       " ...\n",
       " '2023-12-10 00:00:00', '2024-01-14 00:00:00', '2023-11-26 00:00:00',\n",
       " '2023-12-03 00:00:00', '2023-10-29 00:00:00', '2023-11-05 00:00:00',\n",
       " '2023-11-12 00:00:00', '2023-11-19 00:00:00', '2023-12-17 00:00:00',\n",
       " '2023-12-24 00:00:00']\n",
       "Length: 157, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usf['Week Beginning Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_connection():\n",
    "        server = 'mf-enterprise-dev-sql.46ac3df1733c.database.windows.net'\n",
    "        database = 'PWRAPPDB'\n",
    "        driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "        # Establish the database connection using AAD Integrated Authentication\n",
    "        conn_str = (\n",
    "            f'DRIVER={driver};'\n",
    "            f'SERVER=tcp:{server};'\n",
    "            f'DATABASE={database};'\n",
    "            'Authentication=ActiveDirectoryIntegrated'\n",
    "        )\n",
    "\n",
    "        cnxn = pyodbc.connect(conn_str)\n",
    "        cursor = cnxn.cursor()\n",
    "\n",
    "        return cnxn, cursor\n",
    "\n",
    "\n",
    "def filter_rows():\n",
    "    sql_select = \"\"\"\n",
    "    SELECT [Week Beginning Date] \n",
    "    FROM [na_dist].[US_USFoods_Sellout]\n",
    "    GROUP BY [Week Beginning Date] \"\"\"\n",
    "\n",
    "    cnxn, cursor = setup_connection()\n",
    "\n",
    "    cursor.execute(sql_select)\n",
    "\n",
    "    # Fetch the results\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    # Convert the results into a list of dates\n",
    "    dates_in_db = [result[0] if result[0] is not None else None for result in results]\n",
    "    dates_in_db = pd.to_datetime([date for date in dates_in_db if date is not None])\n",
    "\n",
    "    # Commit the transactions\n",
    "    cnxn.commit()\n",
    "\n",
    "    # Close the connection\n",
    "    cursor.close()\n",
    "    cnxn.close()\n",
    "\n",
    "    return dates_in_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_rows(usf[usf['Week Beginning Date']=='2021-02-14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-19 00:00:00\n",
      "2023-12-17 00:00:00\n",
      "2023-12-24 00:00:00\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "weeks_in_db = filter_rows()\n",
    "\n",
    "for week in usf['Week Beginning Date'].unique():\n",
    "    if cnt >= 10:\n",
    "        break\n",
    "    if week not in weeks_in_db:\n",
    "        print(week)\n",
    "        insert_rows(usf[usf['Week Beginning Date']==week])\n",
    "        cnt += 1\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bek_dictionary:\n",
    "    def __init__(self, file_path) -> None:\n",
    "        self.filepath = file_path\n",
    "        self.data = self.process_file()\n",
    "        self.delete_rows()\n",
    "        self.insert_rows()\n",
    "\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def process_file(self):\n",
    "        df = pd.read_excel(self.filepath, sheet_name='Segment Mapping')\n",
    "\n",
    "        columns_to_keep = [\n",
    "            'Business Unit',\n",
    "            'SIC Code',\n",
    "            'SIC Sub',\n",
    "            'COVID Segmentation - L1',\t\n",
    "            'COVID Segmentation - L2',\n",
    "            'COVID Segmentation - (Restaurants)',\n",
    "            'COVID Segmentation - (Restaurants: Sub-Segment)',\n",
    "            'Restaurant Service Type',\n",
    "            'Cuisine Type'\n",
    "        ]\n",
    "\n",
    "        rename_columns = {\n",
    "            'COVID Segmentation - L1':'Segmentation L1',\n",
    "            'COVID Segmentation - L2':'Segmentation L2',\n",
    "            'COVID Segmentation - (Restaurants)':'Restaurants',\n",
    "            'COVID Segmentation - (Restaurants: Sub-Segment)':'Restaurants Sub',\n",
    "            'Restaurant Service Type':'Service Type'\n",
    "        }\n",
    "        \n",
    "        df_clean = df[columns_to_keep].rename(columns=rename_columns)\n",
    "\n",
    "        return df_clean\n",
    "\n",
    "    def setup_connection():\n",
    "        server = 'mf-enterprise-dev-sql.46ac3df1733c.database.windows.net'\n",
    "        database = 'PWRAPPDB'\n",
    "        driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "        # Establish the database connection using AAD Integrated Authentication\n",
    "        conn_str = (\n",
    "            f'DRIVER={driver};'\n",
    "            f'SERVER=tcp:{server};'\n",
    "            f'DATABASE={database};'\n",
    "            'Authentication=ActiveDirectoryIntegrated'\n",
    "        )\n",
    "\n",
    "        cnxn = pyodbc.connect(conn_str)\n",
    "        cursor = cnxn.cursor()\n",
    "\n",
    "        return cnxn, cursor\n",
    "\n",
    "    def delete_rows(self):\n",
    "\n",
    "        sql_delete = \"\"\"\n",
    "        DELETE FROM [na_dist].[US_BEK_Segmentation] \n",
    "        \"\"\"\n",
    "\n",
    "        cnxn, cursor = bek_dictionary.setup_connection()\n",
    "\n",
    "        cursor.execute(sql_delete)\n",
    "\n",
    "        # Commit the transactions\n",
    "        cnxn.commit()\n",
    "\n",
    "        # Close the connection\n",
    "        cursor.close()\n",
    "        cnxn.close()\n",
    "\n",
    "\n",
    "    def setup_miengine():\n",
    "        server = 'mf-enterprise-dev-sql.46ac3df1733c.database.windows.net'\n",
    "        database = 'PWRAPPDB'\n",
    "        driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "        # Establish the database connection using AAD Integrated Authentication\n",
    "        conn_str = URL.create(\n",
    "            'mssql+pyodbc',\n",
    "            query={\n",
    "                'odbc_connect':(\n",
    "                    f'DRIVER={driver};'\n",
    "                    f'SERVER=tcp:{server};'\n",
    "                    f'DATABASE={database};'\n",
    "                    'Authentication=ActiveDirectoryIntegrated;'\n",
    "            )\n",
    "            }\n",
    "        )\n",
    "\n",
    "        engine = create_engine(conn_str, connect_args={\"autocommit\": True}, fast_executemany=True, use_insertmanyvalues=False)\n",
    "\n",
    "        return engine\n",
    "\n",
    "        \n",
    "    def insert_rows(self):\n",
    "        engine = bek_dictionary.setup_miengine()\n",
    "\n",
    "        table_name = 'US_BEK_Segmentation'\n",
    "        schema_name = 'na_dist'\n",
    "\n",
    "        # If the table doesn't exist, it will be created automatically\n",
    "        self.data.to_sql(table_name, con=engine, schema=schema_name, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
